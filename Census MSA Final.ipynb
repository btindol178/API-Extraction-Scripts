{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #make API calls with python\n",
    "import requests #allows us to store results of API call cleanly\n",
    "import json #helps manipulate json\n",
    "import csv # helps with csv files\n",
    "import re #used to clean up cols at the end\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "#os.chdir(\"S:/Strategic Analytics/Customer_Intelligence\")\n",
    "# Census API Key\n",
    "# Go here https://api.census.gov/data/key_signup.html?message=need-terms\n",
    "apiKey = \"e3a3dbad3edfa4d96cb59f65931694b311565c63\"\n",
    "\n",
    "# Here you can find a complete list of variables for the census \n",
    "    #https://api.census.gov/data.html\n",
    "\n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2015():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2015/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2015/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    #newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2016():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2016/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    vaiabledf = pd.read_html('https://api.census.gov/data/2016/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = vaiabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    # # # newColumnNames.append('GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # # # newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2017():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2017/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2017/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[2:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2018():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2018/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2018/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[2:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # #newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2019():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2019/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    \n",
    "    new_df4 = new_df4[[\n",
    "\"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    " \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    " \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    " \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    " \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    " \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    " \"B01001_049E\", \"metropolitan statistical area/micropolitan statistical area\"]]\n",
    "\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2019/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames # Replace the col\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "\n",
    "demographicsMSA2019 = GetCensusMSAAgeGroupDemographics2019()\n",
    "demographicsMSA2018 = GetCensusMSAAgeGroupDemographics2018() # good \n",
    "demographicsMSA2017 = GetCensusMSAAgeGroupDemographics2017() # good \n",
    "demographicsMSA2016 = GetCensusMSAAgeGroupDemographics2016() # Good name naem \n",
    "demographicsMSA2015 = GetCensusMSAAgeGroupDemographics2015() # good \n",
    "\n",
    "\n",
    "demographicsMSA2019['Year'] = 2019\n",
    "demographicsMSA2018['Year'] = 2018\n",
    "demographicsMSA2017['Year'] = 2017\n",
    "demographicsMSA2016['Year'] = 2016\n",
    "demographicsMSA2015['Year'] = 2015\n",
    "\n",
    "demographicsMSA2019 = demographicsMSA2019.loc[:,~demographicsMSA2019.columns.duplicated()]\n",
    "demographicsMSA2018 = demographicsMSA2018.loc[:,~demographicsMSA2018.columns.duplicated()]\n",
    "demographicsMSA2017 = demographicsMSA2017.loc[:,~demographicsMSA2017.columns.duplicated()]\n",
    "demographicsMSA2016 = demographicsMSA2016.loc[:,~demographicsMSA2016.columns.duplicated()]\n",
    "demographicsMSA2015 = demographicsMSA2015.loc[:,~demographicsMSA2015.columns.duplicated()]\n",
    "\n",
    "#clean up the names (this also removes a few differences with the column names that was causing issues w concatenation)\n",
    "def colname_cleanup(data):\n",
    "    data_new = data.copy() #copy into a new pandas dataframe so that it's easier to test\n",
    "    colnames = data_new.columns.values.tolist()\n",
    "    colnames = [col.replace(\":\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total!!\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"!!\",\" \") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total:\",\"Population Total\") for col in colnames]\n",
    "    colnames = [col.replace(\"NAME\",\"MSA Name\") for col in colnames]\n",
    "    colnames = [col.replace(\"metropolitan statistical area/micropolitan statistical area\",\"MSA_Code\") for col in colnames]\n",
    "    colnames = [\"Population \" + col if \"male\" in col.lower() else col for col in colnames]\n",
    "    data_new.columns = colnames\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#need to see whats different for the different df's\n",
    "demographicsMSA2019_f = colname_cleanup(demographicsMSA2019)\n",
    "demographicsMSA2018_f = colname_cleanup(demographicsMSA2018)\n",
    "demographicsMSA2017_f = colname_cleanup(demographicsMSA2017)\n",
    "demographicsMSA2016_f = colname_cleanup(demographicsMSA2016)\n",
    "demographicsMSA2015_f = colname_cleanup(demographicsMSA2015)\n",
    "\n",
    "#make the final data\n",
    "final_data = ( demographicsMSA2015_f.append(demographicsMSA2016_f).append(demographicsMSA2017_f).\n",
    "              append(demographicsMSA2018_f).append(demographicsMSA2019_f) )\n",
    "\n",
    "final_data.columns = final_data.columns.str.replace(' ', '_') \n",
    "\n",
    "\n",
    "#write to an excel file (reads into PBI slightly better)\n",
    "final_data.to_csv(\"Final_MSA_Demographics.csv\")\n",
    "\n",
    "# NEED TO SHIFT ALL OF THE COLUMNS OVER TO THE RIGHT ONE................................!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census = pd.read_csv(\"census_population.csv\")\n",
    "census\n",
    "census.columns = census.columns.str.lower()\n",
    "census['hispanic_pop_pct'] = census.hispanic_pop/census.population\n",
    "census['hispanic_pop_pct'] = census['hispanic_pop_pct'].fillna(0)\n",
    "census = census.dropna()  ## Drop cbsas that are NA\n",
    "census.cbsa = census.cbsa.astype('int').astype('str')\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data2 = final_data[final_data[\"Year\"] == 2019]\n",
    "#final_data2.MSA_Code.astype('str')\n",
    "# final_data2.Estimate_Total.astype('int')\n",
    "#final_data2.Estimate_Total.fillna(0)\n",
    "final_data2[\"MSA_Code2\"] = final_data2[\"MSA_Code\"].astype('str')\n",
    "final_data2['Estimate_Total2'] = final_data2['Estimate_Total'].fillna(0)\n",
    "final_data2['Estimate_Total3'] = final_data2['Estimate_Total2'].astype('int')\n",
    "\n",
    "#cbsa\n",
    "map1 = folium.Map(location=[48, -102], zoom_start=3.5)\n",
    "folium.Choropleth (\n",
    "    geo_data= cbsa,\n",
    "    data=final_data2,\n",
    "    columns=['MSA_Code2', 'Estimate_Total3'],\n",
    "    key_on='feature.properties.CBSAFP', \n",
    "    fill_color='YlGnBu',\n",
    "    line_opacity=0.2,\n",
    "    legend_name='totalpop(%)'\n",
    ").add_to(map1)\n",
    "\n",
    "\n",
    "map1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data2 = final_data[final_data[\"Year\"] == 2019]\n",
    "final_data2.loc[:, 'MSA_Code'] = final_data2['MSA_Code'].astype(str)\n",
    "\n",
    "final_data2.loc[:, 'Estimate_Total'] = final_data2['Estimate_Total'].astype(int) \n",
    "\n",
    "\n",
    "#cbsa\n",
    "map1 = folium.Map(location=[48, -102], zoom_start=3.5)\n",
    "folium.Choropleth (\n",
    "    geo_data= cbsa,\n",
    "    data=final_data2,\n",
    "    columns=['MSA_Code', 'Estimate_Total'],\n",
    "    key_on='feature.properties.CBSAFP', \n",
    "    fill_color='YlGnBu',\n",
    "    line_opacity=0.2,\n",
    "    legend_name='totalpop(%)'\n",
    ").add_to(map1)\n",
    "\n",
    "\n",
    "map1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
