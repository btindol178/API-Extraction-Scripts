{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census Final API Extraction Script All Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MSA Level Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #make API calls with python\n",
    "import requests #allows us to store results of API call cleanly\n",
    "import json #helps manipulate json\n",
    "import csv # helps with csv files\n",
    "import re #used to clean up cols at the end\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "#os.chdir(\"S:/Strategic Analytics/Customer_Intelligence\")\n",
    "# Census API Key\n",
    "# Go here https://api.census.gov/data/key_signup.html?message=need-terms\n",
    "apiKey = \"e3a3dbad3edfa4d96cb59f65931694b311565c63\"\n",
    "\n",
    "# Here you can find a complete list of variables for the census \n",
    "    #https://api.census.gov/data.html\n",
    "\n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2015():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2015/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2015/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    #newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2016():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2016/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    vaiabledf = pd.read_html('https://api.census.gov/data/2016/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = vaiabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    # # # newColumnNames.append('GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # # # newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2017():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2017/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2017/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[2:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2018():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2018/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2018/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[2:51] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.insert(1,'GEO_ID') # add the originoal column names back onto this list in the last position\n",
    "    # #newColumnNames.append('NAME') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames\n",
    "    new_df4 = new_df4[['NAME', 'Estimate!!Total', 'Estimate!!Total!!Male', 'Estimate!!Total!!Male!!Under 5 years', 'Estimate!!Total!!Male!!5 to 9 years', 'Estimate!!Total!!Male!!10 to 14 years', 'Estimate!!Total!!Male!!15 to 17 years', 'Estimate!!Total!!Male!!18 and 19 years',\n",
    " 'Estimate!!Total!!Male!!20 years', 'Estimate!!Total!!Male!!21 years', 'Estimate!!Total!!Male!!22 to 24 years', 'Estimate!!Total!!Male!!25 to 29 years', 'Estimate!!Total!!Male!!30 to 34 years', 'Estimate!!Total!!Male!!35 to 39 years',\n",
    " 'Estimate!!Total!!Male!!40 to 44 years', 'Estimate!!Total!!Male!!45 to 49 years', 'Estimate!!Total!!Male!!50 to 54 years', 'Estimate!!Total!!Male!!55 to 59 years', 'Estimate!!Total!!Male!!60 and 61 years', 'Estimate!!Total!!Male!!62 to 64 years',\n",
    " 'Estimate!!Total!!Male!!65 and 66 years', 'Estimate!!Total!!Male!!67 to 69 years', 'Estimate!!Total!!Male!!70 to 74 years', 'Estimate!!Total!!Male!!75 to 79 years', 'Estimate!!Total!!Male!!80 to 84 years', 'Estimate!!Total!!Male!!85 years and over',\n",
    " 'Estimate!!Total!!Female', 'Estimate!!Total!!Female!!Under 5 years', 'Estimate!!Total!!Female!!5 to 9 years', 'Estimate!!Total!!Female!!10 to 14 years', 'Estimate!!Total!!Female!!15 to 17 years', 'Estimate!!Total!!Female!!18 and 19 years',\n",
    " 'Estimate!!Total!!Female!!20 years', 'Estimate!!Total!!Female!!21 years', 'Estimate!!Total!!Female!!22 to 24 years', 'Estimate!!Total!!Female!!25 to 29 years', 'Estimate!!Total!!Female!!30 to 34 years', 'Estimate!!Total!!Female!!35 to 39 years',\n",
    " 'Estimate!!Total!!Female!!40 to 44 years', 'Estimate!!Total!!Female!!45 to 49 years', 'Estimate!!Total!!Female!!50 to 54 years', 'Estimate!!Total!!Female!!55 to 59 years', 'Estimate!!Total!!Female!!60 and 61 years', 'Estimate!!Total!!Female!!62 to 64 years',\n",
    " 'Estimate!!Total!!Female!!65 and 66 years', 'Estimate!!Total!!Female!!67 to 69 years', 'Estimate!!Total!!Female!!70 to 74 years', 'Estimate!!Total!!Female!!75 to 79 years', 'Estimate!!Total!!Female!!80 to 84 years', 'Estimate!!Total!!Female!!85 years and over',\n",
    " 'metropolitan statistical area/micropolitan statistical area']]\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "def GetCensusMSAAgeGroupDemographics2019():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2019/acs/acs1?get=NAME,group(B01001)&for=metropolitan%20statistical%20area/micropolitan%20statistical%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    \n",
    "    new_df4 = new_df4[[\n",
    "\"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    " \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    " \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    " \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    " \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    " \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    " \"B01001_049E\", \"metropolitan statistical area/micropolitan statistical area\"]]\n",
    "\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2019/acs/acs5/variables.html') # Grab the table of definitions of the variable names \n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the actual description of the variale name) This helps in column understanding\n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('metropolitan statistical area/micropolitan statistical area')  # add the originoal column names back onto this list in the last position\n",
    "    new_df4.columns = newColumnNames # Replace the col\n",
    "    return new_df4 # Return the new dataframe \n",
    "\n",
    "\n",
    "demographicsMSA2019 = GetCensusMSAAgeGroupDemographics2019()\n",
    "demographicsMSA2018 = GetCensusMSAAgeGroupDemographics2018() # good \n",
    "demographicsMSA2017 = GetCensusMSAAgeGroupDemographics2017() # good \n",
    "demographicsMSA2016 = GetCensusMSAAgeGroupDemographics2016() # Good name naem \n",
    "demographicsMSA2015 = GetCensusMSAAgeGroupDemographics2015() # good \n",
    "\n",
    "\n",
    "demographicsMSA2019['Year'] = 2019\n",
    "demographicsMSA2018['Year'] = 2018\n",
    "demographicsMSA2017['Year'] = 2017\n",
    "demographicsMSA2016['Year'] = 2016\n",
    "demographicsMSA2015['Year'] = 2015\n",
    "\n",
    "demographicsMSA2019 = demographicsMSA2019.loc[:,~demographicsMSA2019.columns.duplicated()]\n",
    "demographicsMSA2018 = demographicsMSA2018.loc[:,~demographicsMSA2018.columns.duplicated()]\n",
    "demographicsMSA2017 = demographicsMSA2017.loc[:,~demographicsMSA2017.columns.duplicated()]\n",
    "demographicsMSA2016 = demographicsMSA2016.loc[:,~demographicsMSA2016.columns.duplicated()]\n",
    "demographicsMSA2015 = demographicsMSA2015.loc[:,~demographicsMSA2015.columns.duplicated()]\n",
    "\n",
    "#clean up the names (this also removes a few differences with the column names that was causing issues w concatenation)\n",
    "def colname_cleanup(data):\n",
    "    data_new = data.copy() #copy into a new pandas dataframe so that it's easier to test\n",
    "    colnames = data_new.columns.values.tolist()\n",
    "    colnames = [col.replace(\":\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total!!\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"!!\",\" \") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total:\",\"Population Total\") for col in colnames]\n",
    "    colnames = [col.replace(\"NAME\",\"MSA Name\") for col in colnames]\n",
    "    colnames = [col.replace(\"metropolitan statistical area/micropolitan statistical area\",\"MSA Code\") for col in colnames]\n",
    "    colnames = [\"Population \" + col if \"male\" in col.lower() else col for col in colnames]\n",
    "    data_new.columns = colnames\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#need to see whats different for the different df's\n",
    "demographicsMSA2019_f = colname_cleanup(demographicsMSA2019)\n",
    "demographicsMSA2018_f = colname_cleanup(demographicsMSA2018)\n",
    "demographicsMSA2017_f = colname_cleanup(demographicsMSA2017)\n",
    "demographicsMSA2016_f = colname_cleanup(demographicsMSA2016)\n",
    "demographicsMSA2015_f = colname_cleanup(demographicsMSA2015)\n",
    "\n",
    "#make the final data\n",
    "final_data = ( demographicsMSA2015_f.append(demographicsMSA2016_f).append(demographicsMSA2017_f).\n",
    "              append(demographicsMSA2018_f).append(demographicsMSA2019_f) )\n",
    "\n",
    "#write to an excel file (reads into PBI slightly better)\n",
    "final_data.to_csv(\"Final_MSA_Demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA Name</th>\n",
       "      <th>Estimate Total</th>\n",
       "      <th>Population Male</th>\n",
       "      <th>Population Male Under 5 years</th>\n",
       "      <th>Population Male 5 to 9 years</th>\n",
       "      <th>Population Male 10 to 14 years</th>\n",
       "      <th>Population Male 15 to 17 years</th>\n",
       "      <th>Population Male 18 and 19 years</th>\n",
       "      <th>Population Male 20 years</th>\n",
       "      <th>Population Male 21 years</th>\n",
       "      <th>...</th>\n",
       "      <th>Population Female 60 and 61 years</th>\n",
       "      <th>Population Female 62 to 64 years</th>\n",
       "      <th>Population Female 65 and 66 years</th>\n",
       "      <th>Population Female 67 to 69 years</th>\n",
       "      <th>Population Female 70 to 74 years</th>\n",
       "      <th>Population Female 75 to 79 years</th>\n",
       "      <th>Population Female 80 to 84 years</th>\n",
       "      <th>Population Female 85 years and over</th>\n",
       "      <th>MSA Code</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aberdeen, WA Micro Area</td>\n",
       "      <td>71122</td>\n",
       "      <td>36792</td>\n",
       "      <td>1861</td>\n",
       "      <td>2673</td>\n",
       "      <td>1641</td>\n",
       "      <td>1625</td>\n",
       "      <td>908</td>\n",
       "      <td>1160</td>\n",
       "      <td>518</td>\n",
       "      <td>...</td>\n",
       "      <td>1118</td>\n",
       "      <td>1928</td>\n",
       "      <td>1463</td>\n",
       "      <td>1143</td>\n",
       "      <td>1610</td>\n",
       "      <td>662</td>\n",
       "      <td>640</td>\n",
       "      <td>1575</td>\n",
       "      <td>10140</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adrian, MI Micro Area</td>\n",
       "      <td>98573</td>\n",
       "      <td>49456</td>\n",
       "      <td>2947</td>\n",
       "      <td>2985</td>\n",
       "      <td>3085</td>\n",
       "      <td>2020</td>\n",
       "      <td>1576</td>\n",
       "      <td>606</td>\n",
       "      <td>954</td>\n",
       "      <td>...</td>\n",
       "      <td>1168</td>\n",
       "      <td>2686</td>\n",
       "      <td>1327</td>\n",
       "      <td>1959</td>\n",
       "      <td>2002</td>\n",
       "      <td>1549</td>\n",
       "      <td>1099</td>\n",
       "      <td>1718</td>\n",
       "      <td>10300</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Akron, OH Metro Area</td>\n",
       "      <td>704243</td>\n",
       "      <td>341841</td>\n",
       "      <td>19246</td>\n",
       "      <td>19286</td>\n",
       "      <td>22841</td>\n",
       "      <td>13960</td>\n",
       "      <td>10194</td>\n",
       "      <td>4934</td>\n",
       "      <td>5449</td>\n",
       "      <td>...</td>\n",
       "      <td>9829</td>\n",
       "      <td>15044</td>\n",
       "      <td>9912</td>\n",
       "      <td>12127</td>\n",
       "      <td>12789</td>\n",
       "      <td>9965</td>\n",
       "      <td>8188</td>\n",
       "      <td>11737</td>\n",
       "      <td>10420</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alamogordo, NM Micro Area</td>\n",
       "      <td>64362</td>\n",
       "      <td>32532</td>\n",
       "      <td>2104</td>\n",
       "      <td>2574</td>\n",
       "      <td>1689</td>\n",
       "      <td>758</td>\n",
       "      <td>1094</td>\n",
       "      <td>424</td>\n",
       "      <td>1046</td>\n",
       "      <td>...</td>\n",
       "      <td>912</td>\n",
       "      <td>1192</td>\n",
       "      <td>402</td>\n",
       "      <td>1595</td>\n",
       "      <td>1125</td>\n",
       "      <td>1226</td>\n",
       "      <td>495</td>\n",
       "      <td>745</td>\n",
       "      <td>10460</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Albany, OR Metro Area</td>\n",
       "      <td>120547</td>\n",
       "      <td>59386</td>\n",
       "      <td>3717</td>\n",
       "      <td>3909</td>\n",
       "      <td>3878</td>\n",
       "      <td>2509</td>\n",
       "      <td>1490</td>\n",
       "      <td>636</td>\n",
       "      <td>396</td>\n",
       "      <td>...</td>\n",
       "      <td>1723</td>\n",
       "      <td>2185</td>\n",
       "      <td>1794</td>\n",
       "      <td>2680</td>\n",
       "      <td>2005</td>\n",
       "      <td>2019</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>10540</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    MSA Name Estimate Total Population Male  \\\n",
       "0    Aberdeen, WA Micro Area          71122           36792   \n",
       "1      Adrian, MI Micro Area          98573           49456   \n",
       "2       Akron, OH Metro Area         704243          341841   \n",
       "3  Alamogordo, NM Micro Area          64362           32532   \n",
       "4      Albany, OR Metro Area         120547           59386   \n",
       "\n",
       "  Population Male Under 5 years Population Male 5 to 9 years  \\\n",
       "0                          1861                         2673   \n",
       "1                          2947                         2985   \n",
       "2                         19246                        19286   \n",
       "3                          2104                         2574   \n",
       "4                          3717                         3909   \n",
       "\n",
       "  Population Male 10 to 14 years Population Male 15 to 17 years  \\\n",
       "0                           1641                           1625   \n",
       "1                           3085                           2020   \n",
       "2                          22841                          13960   \n",
       "3                           1689                            758   \n",
       "4                           3878                           2509   \n",
       "\n",
       "  Population Male 18 and 19 years Population Male 20 years  \\\n",
       "0                             908                     1160   \n",
       "1                            1576                      606   \n",
       "2                           10194                     4934   \n",
       "3                            1094                      424   \n",
       "4                            1490                      636   \n",
       "\n",
       "  Population Male 21 years  ... Population Female 60 and 61 years  \\\n",
       "0                      518  ...                              1118   \n",
       "1                      954  ...                              1168   \n",
       "2                     5449  ...                              9829   \n",
       "3                     1046  ...                               912   \n",
       "4                      396  ...                              1723   \n",
       "\n",
       "  Population Female 62 to 64 years Population Female 65 and 66 years  \\\n",
       "0                             1928                              1463   \n",
       "1                             2686                              1327   \n",
       "2                            15044                              9912   \n",
       "3                             1192                               402   \n",
       "4                             2185                              1794   \n",
       "\n",
       "  Population Female 67 to 69 years Population Female 70 to 74 years  \\\n",
       "0                             1143                             1610   \n",
       "1                             1959                             2002   \n",
       "2                            12127                            12789   \n",
       "3                             1595                             1125   \n",
       "4                             2680                             2005   \n",
       "\n",
       "  Population Female 75 to 79 years Population Female 80 to 84 years  \\\n",
       "0                              662                              640   \n",
       "1                             1549                             1099   \n",
       "2                             9965                             8188   \n",
       "3                             1226                              495   \n",
       "4                             2019                             1496   \n",
       "\n",
       "  Population Female 85 years and over MSA Code  Year  \n",
       "0                                1575    10140  2015  \n",
       "1                                1718    10300  2015  \n",
       "2                               11737    10420  2015  \n",
       "3                                 745    10460  2015  \n",
       "4                                1500    10540  2015  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census County Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countyextraction2019():\n",
    "    #https://api.census.gov/data/2019/acs/acs1?get=NAME,B01001_001E&for=county%*:*&in=state:*\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2019/acs/acs1?get=NAME,group(B01001)&for=county:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "    \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "     \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "     \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "     \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "     \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "     \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "     \"B01001_049E\", \"state\",\"county\"]]\n",
    "    new_df4['fips'] = new_df4['state'].astype(str) + new_df4['county'].astype(str)\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2019/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('county') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('fips')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "\n",
    "\n",
    "def countyextraction2018():\n",
    "    #https://api.census.gov/data/2019/acs/acs1?get=NAME,B01001_001E&for=county%*:*&in=state:*\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2018/acs/acs1?get=NAME,group(B01001)&for=county:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "    \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "     \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "     \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "     \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "     \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "     \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "     \"B01001_049E\", \"state\",\"county\"]]\n",
    "    new_df4['fips'] = new_df4['state'].astype(str) + new_df4['county'].astype(str)\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2018/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('county') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('fips')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "\n",
    "def countyextraction2017():\n",
    "    #https://api.census.gov/data/2019/acs/acs1?get=NAME,B01001_001E&for=county%*:*&in=state:*\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2017/acs/acs1?get=NAME,group(B01001)&for=county:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "    \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "     \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "     \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "     \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "     \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "     \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "     \"B01001_049E\", \"state\",\"county\"]]\n",
    "    new_df4['fips'] = new_df4['state'].astype(str) + new_df4['county'].astype(str)\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2017/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('county') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('fips')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "\n",
    "def countyextraction2016():\n",
    "    #https://api.census.gov/data/2019/acs/acs1?get=NAME,B01001_001E&for=county%*:*&in=state:*\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2016/acs/acs1?get=NAME,group(B01001)&for=county:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "    \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "     \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "     \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "     \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "     \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "     \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "     \"B01001_049E\", \"state\",\"county\"]]\n",
    "    new_df4['fips'] = new_df4['state'].astype(str) + new_df4['county'].astype(str)\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2016/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('county') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('fips')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "\n",
    "\n",
    "def countyextraction2015():\n",
    "    #https://api.census.gov/data/2019/acs/acs1?get=NAME,B01001_001E&for=county%*:*&in=state:*\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2015/acs/acs1?get=NAME,group(B01001)&for=county:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers) # now start at row 0 through the whole dataframe and rename the column headers the variable you just instantiated above \n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "    \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "     \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "     \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "     \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "     \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "     \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "     \"B01001_049E\", \"state\",\"county\"]]\n",
    "    new_df4['fips'] = new_df4['state'].astype(str) + new_df4['county'].astype(str)\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2015/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('county') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('fips')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "\n",
    "\n",
    "countyextraction2015 = countyextraction2015()\n",
    "countyextraction2016 = countyextraction2016() # good \n",
    "countyextraction2017 = countyextraction2017() # good \n",
    "countyextraction2018 = countyextraction2018() # Good name naem \n",
    "countyextraction2019 = countyextraction2019() # good \n",
    "\n",
    "\n",
    "countyextraction2015['Year'] = 2015\n",
    "countyextraction2016['Year'] = 2016\n",
    "countyextraction2017['Year'] = 2017\n",
    "countyextraction2018['Year'] = 2018\n",
    "countyextraction2019['Year'] = 2019\n",
    "\n",
    "countyextraction2015 = countyextraction2015.loc[:,~countyextraction2015.columns.duplicated()]\n",
    "countyextraction2016 = countyextraction2016.loc[:,~countyextraction2016.columns.duplicated()]\n",
    "countyextraction2017 = countyextraction2017.loc[:,~countyextraction2017.columns.duplicated()]\n",
    "countyextraction2018 = countyextraction2018.loc[:,~countyextraction2018.columns.duplicated()]\n",
    "countyextraction2019 = countyextraction2019.loc[:,~countyextraction2019.columns.duplicated()]\n",
    "\n",
    "#clean up the names (this also removes a few differences with the column names that was causing issues w concatenation)\n",
    "def colname_cleanup(data):\n",
    "    data_new = data.copy() #copy into a new pandas dataframe so that it's easier to test\n",
    "    colnames = data_new.columns.values.tolist()\n",
    "    colnames = [col.replace(\":\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total!!\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"!!\",\" \") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total:\",\"Population Total\") for col in colnames]\n",
    "    colnames = [col.replace(\"NAME\",\"MSA Name\") for col in colnames]\n",
    "    colnames = [col.replace(\"metropolitan statistical area/micropolitan statistical area\",\"MSA_Code\") for col in colnames]\n",
    "    colnames = [\"Population \" + col if \"male\" in col.lower() else col for col in colnames]\n",
    "    data_new.columns = colnames\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#need to see whats different for the different df's\n",
    "countyextraction2015_f = colname_cleanup(countyextraction2015)\n",
    "countyextraction2016_f = colname_cleanup(countyextraction2016)\n",
    "countyextraction2017_f = colname_cleanup(countyextraction2017)\n",
    "countyextraction2018_f = colname_cleanup(countyextraction2018)\n",
    "countyextraction2019_f = colname_cleanup(countyextraction2019)\n",
    "\n",
    "#make the final data\n",
    "final_data = ( countyextraction2015_f.append(countyextraction2016_f).append(countyextraction2017_f).\n",
    "              append(countyextraction2018_f).append(countyextraction2019_f) )\n",
    "\n",
    "final_data.columns = final_data.columns.str.replace(' ', '_') \n",
    "\n",
    "final_data.to_csv(\"Final_County_Demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA_Name</th>\n",
       "      <th>Estimate_Total</th>\n",
       "      <th>Population_Male</th>\n",
       "      <th>Population_Male_Under_5_years</th>\n",
       "      <th>Population_Male_5_to_9_years</th>\n",
       "      <th>Population_Male_10_to_14_years</th>\n",
       "      <th>Population_Male_15_to_17_years</th>\n",
       "      <th>Population_Male_18_and_19_years</th>\n",
       "      <th>Population_Male_20_years</th>\n",
       "      <th>Population_Male_21_years</th>\n",
       "      <th>...</th>\n",
       "      <th>Population_Female_65_and_66_years</th>\n",
       "      <th>Population_Female_67_to_69_years</th>\n",
       "      <th>Population_Female_70_to_74_years</th>\n",
       "      <th>Population_Female_75_to_79_years</th>\n",
       "      <th>Population_Female_80_to_84_years</th>\n",
       "      <th>Population_Female_85_years_and_over</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>fips</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Martin County, Florida</td>\n",
       "      <td>156283</td>\n",
       "      <td>76619</td>\n",
       "      <td>3089</td>\n",
       "      <td>3074</td>\n",
       "      <td>4314</td>\n",
       "      <td>2617</td>\n",
       "      <td>2529</td>\n",
       "      <td>876</td>\n",
       "      <td>822</td>\n",
       "      <td>...</td>\n",
       "      <td>2205</td>\n",
       "      <td>3570</td>\n",
       "      <td>6195</td>\n",
       "      <td>3801</td>\n",
       "      <td>3807</td>\n",
       "      <td>5468</td>\n",
       "      <td>12</td>\n",
       "      <td>085</td>\n",
       "      <td>12085</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miami-Dade County, Florida</td>\n",
       "      <td>2693117</td>\n",
       "      <td>1305293</td>\n",
       "      <td>80642</td>\n",
       "      <td>75669</td>\n",
       "      <td>78090</td>\n",
       "      <td>48589</td>\n",
       "      <td>31500</td>\n",
       "      <td>17561</td>\n",
       "      <td>17640</td>\n",
       "      <td>...</td>\n",
       "      <td>27188</td>\n",
       "      <td>37663</td>\n",
       "      <td>60103</td>\n",
       "      <td>45062</td>\n",
       "      <td>37354</td>\n",
       "      <td>38426</td>\n",
       "      <td>12</td>\n",
       "      <td>086</td>\n",
       "      <td>12086</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Monroe County, Florida</td>\n",
       "      <td>77482</td>\n",
       "      <td>40676</td>\n",
       "      <td>1759</td>\n",
       "      <td>1573</td>\n",
       "      <td>1685</td>\n",
       "      <td>1048</td>\n",
       "      <td>927</td>\n",
       "      <td>169</td>\n",
       "      <td>309</td>\n",
       "      <td>...</td>\n",
       "      <td>1119</td>\n",
       "      <td>1638</td>\n",
       "      <td>1904</td>\n",
       "      <td>1093</td>\n",
       "      <td>1034</td>\n",
       "      <td>830</td>\n",
       "      <td>12</td>\n",
       "      <td>087</td>\n",
       "      <td>12087</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nassau County, Florida</td>\n",
       "      <td>78444</td>\n",
       "      <td>38819</td>\n",
       "      <td>2130</td>\n",
       "      <td>2491</td>\n",
       "      <td>2196</td>\n",
       "      <td>1820</td>\n",
       "      <td>641</td>\n",
       "      <td>752</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>890</td>\n",
       "      <td>2094</td>\n",
       "      <td>2368</td>\n",
       "      <td>1466</td>\n",
       "      <td>1141</td>\n",
       "      <td>603</td>\n",
       "      <td>12</td>\n",
       "      <td>089</td>\n",
       "      <td>12089</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Okaloosa County, Florida</td>\n",
       "      <td>198664</td>\n",
       "      <td>101303</td>\n",
       "      <td>7170</td>\n",
       "      <td>6663</td>\n",
       "      <td>5370</td>\n",
       "      <td>3480</td>\n",
       "      <td>2606</td>\n",
       "      <td>2374</td>\n",
       "      <td>877</td>\n",
       "      <td>...</td>\n",
       "      <td>2124</td>\n",
       "      <td>3100</td>\n",
       "      <td>4069</td>\n",
       "      <td>3229</td>\n",
       "      <td>2029</td>\n",
       "      <td>2200</td>\n",
       "      <td>12</td>\n",
       "      <td>091</td>\n",
       "      <td>12091</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MSA_Name Estimate_Total Population_Male  \\\n",
       "0      Martin County, Florida         156283           76619   \n",
       "1  Miami-Dade County, Florida        2693117         1305293   \n",
       "2      Monroe County, Florida          77482           40676   \n",
       "3      Nassau County, Florida          78444           38819   \n",
       "4    Okaloosa County, Florida         198664          101303   \n",
       "\n",
       "  Population_Male_Under_5_years Population_Male_5_to_9_years  \\\n",
       "0                          3089                         3074   \n",
       "1                         80642                        75669   \n",
       "2                          1759                         1573   \n",
       "3                          2130                         2491   \n",
       "4                          7170                         6663   \n",
       "\n",
       "  Population_Male_10_to_14_years Population_Male_15_to_17_years  \\\n",
       "0                           4314                           2617   \n",
       "1                          78090                          48589   \n",
       "2                           1685                           1048   \n",
       "3                           2196                           1820   \n",
       "4                           5370                           3480   \n",
       "\n",
       "  Population_Male_18_and_19_years Population_Male_20_years  \\\n",
       "0                            2529                      876   \n",
       "1                           31500                    17561   \n",
       "2                             927                      169   \n",
       "3                             641                      752   \n",
       "4                            2606                     2374   \n",
       "\n",
       "  Population_Male_21_years  ... Population_Female_65_and_66_years  \\\n",
       "0                      822  ...                              2205   \n",
       "1                    17640  ...                             27188   \n",
       "2                      309  ...                              1119   \n",
       "3                       42  ...                               890   \n",
       "4                      877  ...                              2124   \n",
       "\n",
       "  Population_Female_67_to_69_years Population_Female_70_to_74_years  \\\n",
       "0                             3570                             6195   \n",
       "1                            37663                            60103   \n",
       "2                             1638                             1904   \n",
       "3                             2094                             2368   \n",
       "4                             3100                             4069   \n",
       "\n",
       "  Population_Female_75_to_79_years Population_Female_80_to_84_years  \\\n",
       "0                             3801                             3807   \n",
       "1                            45062                            37354   \n",
       "2                             1093                             1034   \n",
       "3                             1466                             1141   \n",
       "4                             3229                             2029   \n",
       "\n",
       "  Population_Female_85_years_and_over state county   fips  Year  \n",
       "0                                5468    12    085  12085  2019  \n",
       "1                               38426    12    086  12086  2019  \n",
       "2                                 830    12    087  12087  2019  \n",
       "3                                 603    12    089  12089  2019  \n",
       "4                                2200    12    091  12091  2019  \n",
       "\n",
       "[5 rows x 54 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zipcode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zctaextraction2019():\n",
    "    indicators = requests.get(\"https://api.census.gov/data/2019/acs/acs5?get=NAME,group(B01001)&for=zip%20code%20tabulation%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "    indicatorsAllJSON = indicators.json()\n",
    "    dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "    headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "    new_df  = pd.DataFrame(dfAll.values[1:], columns=headers)\n",
    "    new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "    new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "    new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "    new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "    new_df4 = new_df4[[\n",
    "        \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "         \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "         \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "         \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "         \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "         \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "         \"B01001_049E\", \"state\",\"zip code tabulation area\"]]\n",
    "    variabledf = pd.read_html('https://api.census.gov/data/2019/acs/acs5/variables.html')\n",
    "    variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "    variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "    filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "    filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "    filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "    filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "    newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "    newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "    newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "    newColumnNames.append('zip code tabulation area')  # add the originoal column names back onto this list \n",
    "    new_df4.columns = newColumnNames # Replace th\n",
    "    return new_df4\n",
    "\n",
    "# NOT ALL YEARS HAVE A STATE COLUMN FOR NOW JUST USE 2019\n",
    "\n",
    "# def zctaextraction2018():\n",
    "#     indicators = requests.get(\"https://api.census.gov/data/2018/acs/acs5?get=NAME,group(B01001)&for=zip%20code%20tabulation%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "#     indicatorsAllJSON = indicators.json()\n",
    "#     dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "#     headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "#     new_df  = pd.DataFrame(dfAll.values[1:], columns=headers)\n",
    "#     new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "#     new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "#     new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "#     new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "#     new_df4 = new_df4[[\n",
    "#         \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "#          \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "#          \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "#          \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "#          \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "#          \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "#          \"B01001_049E\", \"state\",\"zip code tabulation area\"]]\n",
    "#     variabledf = pd.read_html('https://api.census.gov/data/2018/acs/acs5/variables.html')\n",
    "#     variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "#     variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "#     filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "#     filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "#     filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "#     filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "#     newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "#     newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "#     newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "#     newColumnNames.append('zip code tabulation area')  # add the originoal column names back onto this list \n",
    "#     new_df4.columns = newColumnNames # Replace th\n",
    "#     return new_df4\n",
    "\n",
    "# def zctaextraction2017():\n",
    "#     indicators = requests.get(\"https://api.census.gov/data/2017/acs/acs5?get=NAME,group(B01001)&for=zip%20code%20tabulation%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "#     indicatorsAllJSON = indicators.json()\n",
    "#     dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "#     headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "#     new_df  = pd.DataFrame(dfAll.values[1:], columns=headers)\n",
    "#     new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "#     new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "#     new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "#     new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "#     new_df4 = new_df4[[\n",
    "#         \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "#          \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "#          \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "#          \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "#          \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "#          \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "#          \"B01001_049E\", \"state\",\"zip code tabulation area\"]]\n",
    "#     variabledf = pd.read_html('https://api.census.gov/data/2017/acs/acs5/variables.html')\n",
    "#     variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "#     variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "#     filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "#     filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "#     filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "#     filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "#     newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "#     newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "#     newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "#     newColumnNames.append('zip code tabulation area')  # add the originoal column names back onto this list \n",
    "#     new_df4.columns = newColumnNames # Replace th\n",
    "#     return new_df4\n",
    "\n",
    "# def zctaextraction2016():\n",
    "#     indicators = requests.get(\"https://api.census.gov/data/2016/acs/acs5?get=NAME,group(B01001)&for=zip%20code%20tabulation%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "#     indicatorsAllJSON = indicators.json()\n",
    "#     dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "#     headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "#     new_df  = pd.DataFrame(dfAll.values[1:], columns=headers)\n",
    "#     new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "#     new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "#     new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "#     new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "#     new_df4 = new_df4[[\n",
    "#         \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "#          \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "#          \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "#          \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "#          \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "#          \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "#          \"B01001_049E\", \"state\",\"zip code tabulation area\"]]\n",
    "#     variabledf = pd.read_html('https://api.census.gov/data/2016/acs/acs5/variables.html')\n",
    "#     variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "#     variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "#     filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "#     filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "#     filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "#     filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "#     newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "#     newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "#     newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "#     newColumnNames.append('zip code tabulation area')  # add the originoal column names back onto this list \n",
    "#     new_df4.columns = newColumnNames # Replace th\n",
    "#     return new_df4\n",
    "\n",
    "# def zctaextraction2015():\n",
    "#     indicators = requests.get(\"https://api.census.gov/data/2015/acs/acs5?get=NAME,group(B01001)&for=zip%20code%20tabulation%20area:*&key=e3a3dbad3edfa4d96cb59f65931694b311565c63\")\n",
    "#     indicatorsAllJSON = indicators.json()\n",
    "#     dfAll = pd.DataFrame(indicatorsAllJSON)\n",
    "#     headers = dfAll.iloc[0] # Get the column headers in the first row at index position 0 to make them column names\n",
    "#     new_df  = pd.DataFrame(dfAll.values[1:], columns=headers)\n",
    "#     new_df2 = new_df.loc[:, ~new_df.columns.str.endswith('EA')] # remove columns with names that end with EA\n",
    "#     new_df3 = new_df2.loc[:, ~new_df2.columns.str.endswith('MA')] # remove columns with names that end with MA\n",
    "#     new_df4 = new_df3.loc[:, ~new_df3.columns.str.endswith('M')] # remove columns with names that end with M\n",
    "#     new_df4 = new_df4.loc[:,~new_df4.columns.duplicated()]\n",
    "#     new_df4 = new_df4[[\n",
    "#         \"NAME\", \"B01001_001E\", \"B01001_002E\", \"B01001_003E\", \"B01001_004E\", \"B01001_005E\", \"B01001_006E\", \"B01001_007E\", \"B01001_008E\",\n",
    "#          \"B01001_009E\", \"B01001_010E\", \"B01001_011E\", \"B01001_012E\", \"B01001_013E\", \"B01001_014E\", \"B01001_015E\", \"B01001_016E\",\n",
    "#          \"B01001_017E\", \"B01001_018E\", \"B01001_019E\", \"B01001_020E\", \"B01001_021E\", \"B01001_022E\", \"B01001_023E\", \"B01001_024E\",\n",
    "#          \"B01001_025E\", \"B01001_026E\", \"B01001_027E\", \"B01001_028E\", \"B01001_029E\", \"B01001_030E\", \"B01001_031E\", \"B01001_032E\",\n",
    "#          \"B01001_033E\", \"B01001_034E\", \"B01001_035E\", \"B01001_036E\", \"B01001_037E\", \"B01001_038E\", \"B01001_039E\", \"B01001_040E\",\n",
    "#          \"B01001_041E\", \"B01001_042E\", \"B01001_043E\", \"B01001_044E\", \"B01001_045E\", \"B01001_046E\", \"B01001_047E\", \"B01001_048E\",\n",
    "#          \"B01001_049E\", \"state\",\"zip code tabulation area\"]]\n",
    "#     variabledf = pd.read_html('https://api.census.gov/data/2015/acs/acs5/variables.html')\n",
    "#     variabledf = variabledf[0] # grab the first element of the html which is the actual table\n",
    "#     variablenamedf = pd.DataFrame(variabledf) # make it into a dataframe \n",
    "#     filterRows = list(new_df4.columns) # take theMSA data and get the column names (AKA variable names) to filter rows in the variable definitions table\n",
    "#     filterRows2 =filterRows[1:50] # # exclude the MSA names  and geoid columns for the filtering of the rows\n",
    "#     filteredvariabledf = variablenamedf.Name.isin(filterRows2) # filter the rows of the variable name table with the msa column names\n",
    "#     filtered_df = variablenamedf[filteredvariabledf] # return a new filtered dataframe\n",
    "#     newColumnNames = list(filtered_df.Label) # Get the second column of the newly filtered variable definitions table (the \n",
    "#     newColumnNames.insert(0,'NAME') # add the originoal column names back onto this list in the first position\n",
    "#     newColumnNames.append('state') # add the originoal column names back onto this list in the last position\n",
    "#     newColumnNames.append('zip code tabulation area')  # add the originoal column names back onto this list \n",
    "#     new_df4.columns = newColumnNames # Replace th\n",
    "#     return new_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zctaextraction2015 = zctaextraction2015()\n",
    "# zctaextraction2016 = zctaextraction2016() # good \n",
    "# zctaextraction2017 = zctaextraction2017() # good \n",
    "# zctaextraction2018 = zctaextraction2018() # Good name naem \n",
    "zctaextraction2019 = zctaextraction2019() # good \n",
    "\n",
    "\n",
    "zctaextraction2019['Year'] = 2019\n",
    "# zctaextraction2018['Year'] = 2018\n",
    "# zctaextraction2017['Year'] = 2017\n",
    "# zctaextraction2016['Year'] = 2016\n",
    "#zctaextraction2015['Year'] = 2015\n",
    "\n",
    "# zctaextraction2015 = zctaextraction2015.loc[:,~zctaextraction2015.columns.duplicated()]\n",
    "# zctaextraction2016 = zctaextraction2016.loc[:,~zctaextraction2016.columns.duplicated()]\n",
    "# zctaextraction2017 = zctaextraction2017.loc[:,~zctaextraction2017.columns.duplicated()]\n",
    "# zctaextraction2018 = zctaextraction2018.loc[:,~zctaextraction2018.columns.duplicated()]\n",
    "zctaextraction2019 = zctaextraction2019.loc[:,~zctaextraction2019.columns.duplicated()]\n",
    "\n",
    "#clean up the names (this also removes a few differences with the column names that was causing issues w concatenation)\n",
    "def colname_cleanup(data):\n",
    "    data_new = data.copy() #copy into a new pandas dataframe so that it's easier to test\n",
    "    colnames = data_new.columns.values.tolist()\n",
    "    colnames = [col.replace(\":\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total!!\",\"\") for col in colnames]\n",
    "    colnames = [col.replace(\"!!\",\" \") for col in colnames]\n",
    "    colnames = [col.replace(\"Estimate!!Total:\",\"Population Total\") for col in colnames]\n",
    "    colnames = [col.replace(\"NAME\",\"MSA Name\") for col in colnames]\n",
    "    colnames = [col.replace(\"metropolitan statistical area/micropolitan statistical area\",\"MSA_Code\") for col in colnames]\n",
    "    colnames = [\"Population \" + col if \"male\" in col.lower() else col for col in colnames]\n",
    "    data_new.columns = colnames\n",
    "    return data_new\n",
    "\n",
    "\n",
    "#need to see whats different for the different df's\n",
    "#zctaextraction2015_f = colname_cleanup(zctaextraction2015)\n",
    "# zctaextraction2016_f = colname_cleanup(zctaextraction2016)\n",
    "# zctaextraction2017_f = colname_cleanup(zctaextraction2017)\n",
    "# zctaextraction2018_f = colname_cleanup(zctaextraction2018)\n",
    "zctaextraction2019_f = colname_cleanup(zctaextraction2019)\n",
    "\n",
    "#make the final data\n",
    "final_data = ( zctaextraction2015_f.append(zctaextraction2016_f).append(zctaextraction2017_f).\n",
    "              append(zctaextraction2018_f).append(zctaextraction2019_f) )\n",
    "\n",
    "final_data.columns = final_data.columns.str.replace(' ', '_') \n",
    "\n",
    "final_data.to_csv(\"Final_Zcta_Demographics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
